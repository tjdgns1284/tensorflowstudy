# 텐서플로우 자습 

[toc]

## 케라스 

케라스란 파이썬 라이브러리로 머신러닝과 관련된 기능들을 쉽게 사용할수 있게 구현한것이다 .

머신러닝의 과정은 Data 준비 - > 모델정의 -> 손실함수/옵티마이저(loss/optimizer) 설정 후 compile -> 학습 /추론 (fit)



### 용어 정리 

#### 클래스 불균형 

 2 3 4  4 2 1 3 4 9 4 2 1 4 3 과 같이 중간에 9같은 것이 끼어있어서 각 클래스 간 불균형이 있는 상태 이런상태에선 학습을 정확하게 하기 어려움 이러한 데이터는 은행사기, 불량 과 같은 데이터에서 발생함 



#### 과대표집 과 과대 적합 

과대표집이란 data의 양이 부족할 때 이를 복사해서 학습하는 경우에 그냥 복사할 경우 균형잡힌 학습이 어려워 과대적합이 발생하는 것을 말한다 과대적합상태에선 학습데이터를 test할때는 잘하지만 새로운 데이터를 테스트 할때 약점을 보이는 상태를 의미한다 사람으로 말하자면 단순암기만 한 상태라고 할수있다. 

과소 표집은 클래스의 불균형을 해소하기 위해 가중치를 없애 버린상태로 이경우 학습할 데이터의 양이 너무 적어지게 된다. 

과소 적합은 data가 부족하여 생기는 문제로 사람으로 치면 공부를안한상태이다. 



#### 회귀 / 분류 

회귀란 독립변수의 data를 통해 종속변수의 값을 예측/추론 하는 것이 회귀이다 .

분류는 선다형문제를 푸는 것으로 이진분류(O,X) / 다중분류 (택 1)/ 다중 레이블 분류 (모두 고르시오) 가 있다. 



#### 원  핫 인코딩 

다중분류의 한종류이다. 자연어 처리에서 사용된다 . (잘모르겠음 )



#### 데이터의 분류 

데이터는 학습데이터 / 검증 데이터/ 테스트 데이터로 나누어 지며 

학습후 검증을통해 이 학습이 적합하였는지를 평가하고 적합하면 테스트를 하고 적합하지않으면 모델과 데이터를 수정하여 다시 학습하는 구조를 가진다. 

이 검증 과정을 교차검증이라하는데 교차검증에는 홀드아웃 K폴드 등의 방법이 있다. 

홀드아웃은 일정 비율로 data를 나누어서 학습/검증/test를 진행하는 것이다 .

K폴드의 경우 data를 학습/test로 나눈 다음 학습data를 k분할로 나눈다 

이후 

1번째 학습데이터를 검증데이터로 사용하고 나머지를 학습데이터로사용한 경우 - fold 1 

2번째 학습데이터를 검증데이터로 사용하고 나머지를 학습데이터로사용한 경우 - fold 2

.

.

.

k번째 학습데이터를 검증데이터로 사용하고 나머지를 학습데이터로사용한 경우 - fold k

이러한 fold case들의 결과를 종합하여 학습하는 방법이다. 



#### 하이퍼 파라미터 

머신러닝과정중에 진행을 하면서 알아가야 하는 파라미터들이 있는데 이를 하이퍼 파라미터라고한다 

하이퍼 파라미터의 예시에는 배치 에폭 학습률 등이 있다. 



#### Batch(배치)

일반적으로 학습시 data를 다사용하거나 하나만 사용하여 학습을하는데 이경우 비효율적이거나 문제가 있거나 하게됨 

이를 해결하기 위해 batch에 data를 나눠담으면 메모리/하드웨어적으로 굉장히 효율이좋아짐 



#### Epochs(에폭) / Step

에폭은 전체데이터를 반복해서 학습할 횟수이고 

스텝은 배치하나를 학습이 완료되면 모델 data를 업데이트 하는것이다 

e.g ) 배치크기 100 에폭 10 배치갯수 32개 면 전체 데이터의 크기는 32x100이고 학습할 데이터의 양은 3200x10 이된다.  이 때 스탭의 수는 32000/32로 1000회이다 . 



#### 지도학습/ 비지도학습 

지도학습은 우리가 답을 알려주며 학습하는것이다. 햄버거 사진을 보여주며 이건 햄버거다 라고 가르치는 방법이다. 

비지도학습은 햄버거 사진들을 여러장보여주며 같은 햄버거 끼리 묶어서 분류해보게 만드는 것을 의미한다. 



#### 혼동 행열 

평가에 사용되는 행열로 

|      |      | 예상                     |                         |
| ---- | ---- | ------------------------ | ----------------------- |
|      |      | T                        | F                       |
| 실제 | T    | TP (True인걸 맞춤 )      | FN(True인걸 False라함 ) |
|      | F    | FP (False인걸 True라함 ) | TN(False인걸 맞춤 )     |

이러한 행열이다 .

이때 정확도 정밀도 재현율 특이도 라는 개념이 등장하게 된다 

정확도는
$$
Acc = (TP+TN)/(TP+TN+FP+FN)
$$
로 정확하게 예측한 확률을 의미한다



정밀도는
$$
Precision = (TP)/(TP+FP)
$$
로 T라 예측한것중에 정말 T인것의 비율을 의미한다



재현율은
$$
Recall = (TP)/(TP+FN)
$$
로 실제 T인것중 T라 예측한 비율을 의미한다 이둘은 서로 배타적인 관계에 있어서 이둘의 관계를 F-1스코어를 통해 한쪽으로 쏠리는 것을 방지한다 

F-1스코어는 
$$
F-1 = 2*Precision*Recall/(Precision*Recall)
$$
을 따른다 

특이도는
$$
Specificity = (TN)/(FP+TN)
$$
로 F라 예측한것중에 정말 F인것의 비율을 의미한다

재현율과 1-특이도를 지표로 사용하여 곡선을 만들수 있는데 이 곡선을 ROC 곡선이라고 한다 이 곡선은 

재현율은 1에 가까워지고 1-특이도는 0에 가까워질수록 좋은 모델임을 나타내는 곡선이다 . 









## Tensor

tensor은 텐서플로우의 기본 자료구조형으로 rank를 갖는데 리스트의 차원이랑같은 개념이다 .

tensor object는 numpy() 메서드를 통해 넘파이 로 바꿀수 있고 

npobject는 tf.convert_to_tensor(npobj)를 통해 tensor로 바꿀수 있다 .



@tf.function 데코레이터는 파이썬함수를 그래프로만들어서 실행하고 이를통해 성능을향상시킬수 있는 데코레이터이다 .



퍼셉트론이란 여러개의 신호를 받아 활성화함수를 통해 하나의 신호로 출력하는 것이다. 한층에서 여러개를 사용할수 있고 이를 통해 모델을 구성함 은닉유닛이라고도 함 



또한 가중치를 업데이트 해가면서 문제를 해결하는 것이좋은데  이를 위해 경사하강법을 사용함 SGD,RMSProp같은 옵티마이져가 대표적인 경사하강법임 

옵티마이져: 최적화를 위해 어떤 방법을 쓸지 결정 

loss:  최적화 시킬 손실함수를 결정함 

metrics: 평가지표로 객체/문자열로 지정해서 사용함 



이중분류: sigmoid  + binary_crossentropy

다중분류: softmax  + categorical_crossentropy

다중레이블: sigmoid  + binary_crossentropy

회귀: mse  + mae